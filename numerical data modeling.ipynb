{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:30:04.737962Z",
     "iopub.status.busy": "2022-08-04T13:30:04.736698Z",
     "iopub.status.idle": "2022-08-04T13:30:04.892675Z",
     "shell.execute_reply": "2022-08-04T13:30:04.891505Z",
     "shell.execute_reply.started": "2022-08-04T13:30:04.737917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15474, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>street</th>\n",
       "      <th>citi</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1317 Van Buren Avenue</td>\n",
       "      <td>Salton City, CA</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1560</td>\n",
       "      <td>201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124 C Street W</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713</td>\n",
       "      <td>228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2304 Clark Road</td>\n",
       "      <td>Imperial, CA</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>273950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>755 Brawley Avenue</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2207 R Carrillo Court</td>\n",
       "      <td>Calexico, CA</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2547</td>\n",
       "      <td>385100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                 street             citi  n_citi  bed  bath  sqft  \\\n",
       "0         0  1317 Van Buren Avenue  Salton City, CA     317    3   2.0  1560   \n",
       "1         1         124 C Street W      Brawley, CA      48    3   2.0   713   \n",
       "2         2        2304 Clark Road     Imperial, CA     152    3   1.0   800   \n",
       "3         3     755 Brawley Avenue      Brawley, CA      48    3   1.0  1082   \n",
       "4         4  2207 R Carrillo Court     Calexico, CA      55    4   3.0  2547   \n",
       "\n",
       "    price  \n",
       "0  201900  \n",
       "1  228500  \n",
       "2  273950  \n",
       "3  350000  \n",
       "4  385100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15474 entries, 0 to 15473\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   image_id  15474 non-null  int64  \n",
      " 1   street    15474 non-null  object \n",
      " 2   citi      15474 non-null  object \n",
      " 3   n_citi    15474 non-null  int64  \n",
      " 4   bed       15474 non-null  int64  \n",
      " 5   bath      15474 non-null  float64\n",
      " 6   sqft      15474 non-null  int64  \n",
      " 7   price     15474 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 967.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15474.000000</td>\n",
       "      <td>15474.000000</td>\n",
       "      <td>15474.000000</td>\n",
       "      <td>15474.000000</td>\n",
       "      <td>15474.000000</td>\n",
       "      <td>1.547400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7736.500000</td>\n",
       "      <td>216.597518</td>\n",
       "      <td>3.506398</td>\n",
       "      <td>2.453251</td>\n",
       "      <td>2173.913209</td>\n",
       "      <td>7.031209e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4467.103368</td>\n",
       "      <td>112.372985</td>\n",
       "      <td>1.034838</td>\n",
       "      <td>0.958742</td>\n",
       "      <td>1025.339617</td>\n",
       "      <td>3.769762e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1.950000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3868.250000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1426.000000</td>\n",
       "      <td>4.450000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7736.500000</td>\n",
       "      <td>222.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>6.390000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11604.750000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2737.750000</td>\n",
       "      <td>8.349750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15473.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>17667.000000</td>\n",
       "      <td>2.000000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id        n_citi           bed          bath          sqft  \\\n",
       "count  15474.000000  15474.000000  15474.000000  15474.000000  15474.000000   \n",
       "mean    7736.500000    216.597518      3.506398      2.453251   2173.913209   \n",
       "std     4467.103368    112.372985      1.034838      0.958742   1025.339617   \n",
       "min        0.000000      0.000000      1.000000      0.000000    280.000000   \n",
       "25%     3868.250000    119.000000      3.000000      2.000000   1426.000000   \n",
       "50%     7736.500000    222.500000      3.000000      2.100000   1951.000000   \n",
       "75%    11604.750000    315.000000      4.000000      3.000000   2737.750000   \n",
       "max    15473.000000    414.000000     12.000000     36.000000  17667.000000   \n",
       "\n",
       "              price  \n",
       "count  1.547400e+04  \n",
       "mean   7.031209e+05  \n",
       "std    3.769762e+05  \n",
       "min    1.950000e+05  \n",
       "25%    4.450000e+05  \n",
       "50%    6.390000e+05  \n",
       "75%    8.349750e+05  \n",
       "max    2.000000e+06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\ruijiec\\Downloads\\data\\socal2.csv')\n",
    "print(data.shape)\n",
    "display(data.head())\n",
    "display(data.info())\n",
    "display(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:30:05.730689Z",
     "iopub.status.busy": "2022-08-04T13:30:05.727695Z",
     "iopub.status.idle": "2022-08-04T13:31:43.728963Z",
     "shell.execute_reply": "2022-08-04T13:31:43.727973Z",
     "shell.execute_reply.started": "2022-08-04T13:30:05.730643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15473\n",
      "2600\n",
      "4754\n",
      "10000\n",
      "12498\n",
      "15469\n",
      "{(311, 415, 3), (350, 350, 3), (350, 525, 4)}\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "print(data.image_id.max())\n",
    "imgs = []\n",
    "img_shapes = []\n",
    "c = 0\n",
    "for i in  range(data.image_id.max()):\n",
    "    try:\n",
    "        image = Image.open('C:/Users/ruijiec/Downloads/data/socal2/socal_pics/{}.jpg'.format(i))\n",
    "    #     plt.imshow(image)\n",
    "    #     plt.show()\n",
    "        img_data = asarray(image)\n",
    "    #     np.transpose(data, (2,0,1)).shape\n",
    "        imgs.append(np.transpose(img_data, (2,0,1)))\n",
    "        img_shapes.append(img_data.shape)\n",
    "        if (311, 415, 3) != img_data.shape:\n",
    "            c+=1\n",
    "    except:\n",
    "        print(i)\n",
    "    \n",
    "print(len(imgs))\n",
    "print(set(img_shapes))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:31:43.736020Z",
     "iopub.status.busy": "2022-08-04T13:31:43.733588Z",
     "iopub.status.idle": "2022-08-04T13:32:28.393705Z",
     "shell.execute_reply": "2022-08-04T13:32:28.392584Z",
     "shell.execute_reply.started": "2022-08-04T13:31:43.735979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "181\n",
      "[0, 14, 373, 477, 482, 550, 717, 747, 752, 903, 1128, 1208, 1312, 1697, 1725, 1908, 2385, 2554, 2600, 2729, 3545, 3747, 4754, 4923, 4925, 4926, 4927, 4928, 4929, 4936, 4949, 5013, 5037, 5062, 5117, 5118, 5119, 5120, 5121, 5124, 5129, 5134, 5135, 5136, 5177, 5180, 5312, 5313, 5368, 5413, 5510, 5511, 5524, 5530, 5533, 5551, 5591, 5640, 5648, 5657, 5705, 5712, 5713, 5719, 5720, 5725, 5728, 5744, 5757, 5782, 5833, 5862, 5906, 5913, 5924, 5925, 5934, 5935, 5941, 5942, 5953, 6000, 6108, 6109, 6114, 6115, 6142, 6165, 6304, 6305, 6306, 6322, 6483, 6488, 6489, 6502, 6503, 6506, 6509, 6510, 6511, 6526, 6649, 6672, 6697, 6698, 6701, 6714, 6770, 6835, 6836, 6854, 6872, 6873, 6893, 6895, 6948, 6969, 6992, 7029, 7033, 7037, 7039, 7065, 7090, 7093, 7108, 7144, 7162, 7163, 7193, 7291, 7297, 7321, 7333, 7336, 7484, 7485, 7493, 7496, 7518, 7523, 7526, 7535, 7542, 7677, 7678, 7681, 7682, 7684, 7685, 7736, 7743, 7751, 7816, 7874, 7876, 7877, 7888, 7907, 7969, 8238, 8709, 8809, 8886, 8895, 9081, 9194, 9492, 10000, 10488, 10609, 11821, 11822, 11998, 12024, 12498, 12623, 14476, 14481, 14875]\n"
     ]
    }
   ],
   "source": [
    "exclude_list = []\n",
    "for i in  range(data.image_id.max()):\n",
    "    image = Image.open('C:/Users/ruijiec/Downloads/data/socal2/socal_pics/{}.jpg'.format(i))\n",
    "    temp = asarray(image)\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    if (311, 415, 3) != temp.shape:\n",
    "        exclude_list.append(i)\n",
    "\n",
    "print(len(exclude_list))\n",
    "print(exclude_list)\n",
    "\n",
    "# exclude_list = [0, 14, 373, 477, 482, 550, 717, 747, 752, 903, 1128, 1208, 1312, 1697, 1725, 1908, 2385, 2554, 2600, 2729, 3545, 3747, 4754, 4923, 4925, 4926, 4927, 4928, 4929, 4936, 4949, 5013, 5037, 5062, 5117, 5118, 5119, 5120, 5121, 5124, 5129, 5134, 5135, 5136, 5177, 5180, 5312, 5313, 5368, 5413, 5510, 5511, 5524, 5530, 5533, 5551, 5591, 5640, 5648, 5657, 5705, 5712, 5713, 5719, 5720, 5725, 5728, 5744, 5757, 5782, 5833, 5862, 5906, 5913, 5924, 5925, 5934, 5935, 5941, 5942, 5953, 6000, 6108, 6109, 6114, 6115, 6142, 6165, 6304, 6305, 6306, 6322, 6483, 6488, 6489, 6502, 6503, 6506, 6509, 6510, 6511, 6526, 6649, 6672, 6697, 6698, 6701, 6714, 6770, 6835, 6836, 6854, 6872, 6873, 6893, 6895, 6948, 6969, 6992, 7029, 7033, 7037, 7039, 7065, 7090, 7093, 7108, 7144, 7162, 7163, 7193, 7291, 7297, 7321, 7333, 7336, 7484, 7485, 7493, 7496, 7518, 7523, 7526, 7535, 7542, 7677, 7678, 7681, 7682, 7684, 7685, 7736, 7743, 7751, 7816, 7874, 7876, 7877, 7888, 7907, 7969, 8238, 8709, 8809, 8886, 8895, 9081, 9194, 9492, 10000, 10488, 10609, 11821, 11822, 11998, 12024, 12498, 12623, 14476, 14481, 14875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:32:28.396034Z",
     "iopub.status.busy": "2022-08-04T13:32:28.395373Z",
     "iopub.status.idle": "2022-08-04T13:32:28.410585Z",
     "shell.execute_reply": "2022-08-04T13:32:28.409633Z",
     "shell.execute_reply.started": "2022-08-04T13:32:28.395996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count = data.isnull().sum().sort_values(ascending = False)\n",
    "null_count = null_count[null_count>0]\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:32:28.412193Z",
     "iopub.status.busy": "2022-08-04T13:32:28.411868Z",
     "iopub.status.idle": "2022-08-04T13:32:28.428975Z",
     "shell.execute_reply": "2022-08-04T13:32:28.427873Z",
     "shell.execute_reply.started": "2022-08-04T13:32:28.412144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10705, 5)\n",
      "(10705,)\n",
      "(4588, 5)\n",
      "(4588,)\n"
     ]
    }
   ],
   "source": [
    "temp = data[~data.image_id.isin(exclude_list)]\n",
    "x_train, x_test, y_train, y_test = train_test_split(temp.drop(['price', 'citi', 'street'], axis=1), temp['price'], test_size=0.30, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:32:28.431387Z",
     "iopub.status.busy": "2022-08-04T13:32:28.430978Z",
     "iopub.status.idle": "2022-08-04T13:32:58.562107Z",
     "shell.execute_reply": "2022-08-04T13:32:58.560870Z",
     "shell.execute_reply.started": "2022-08-04T13:32:28.431348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images:  10705\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt=0\n",
    "images_path='C:/Users/ruijiec/Downloads/data/socal2/socal_pics'\n",
    "x_train_images=np.zeros((x_train.shape[0],64,64,3),dtype='uint32')\n",
    "for i in x_train.image_id:\n",
    "    sample=cv2.imread(images_path+'/'+str(i)+'.jpg')\n",
    "    imgs=cv2.resize(sample,(64,64))\n",
    "    x_train_images[cnt]=imgs\n",
    "    cnt+=1\n",
    "\n",
    "print(\"No. of images: \",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:32:58.567699Z",
     "iopub.status.busy": "2022-08-04T13:32:58.567398Z",
     "iopub.status.idle": "2022-08-04T13:33:10.931304Z",
     "shell.execute_reply": "2022-08-04T13:33:10.930247Z",
     "shell.execute_reply.started": "2022-08-04T13:32:58.567671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images:  4588\n",
      "Wall time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt=0\n",
    "images_path='C:/Users/ruijiec/Downloads/data/socal2/socal_pics'\n",
    "x_test_images=np.zeros((x_test.shape[0],64,64,3),dtype='uint32')\n",
    "for i in x_test.image_id:\n",
    "    sample=cv2.imread(images_path+'/'+str(i)+'.jpg')\n",
    "    imgs=cv2.resize(sample,(64,64))\n",
    "    x_test_images[cnt]=imgs\n",
    "    cnt+=1\n",
    "\n",
    "print(\"No. of images: \",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:10.933275Z",
     "iopub.status.busy": "2022-08-04T13:33:10.932592Z",
     "iopub.status.idle": "2022-08-04T13:33:10.945127Z",
     "shell.execute_reply": "2022-08-04T13:33:10.943897Z",
     "shell.execute_reply.started": "2022-08-04T13:33:10.933236Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset_text(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x[['n_citi','bed', 'bath', 'sqft']].values).float()\n",
    "        #self.img = img\n",
    "        self.y = torch.tensor(y.values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        #img = self.img[idx]\n",
    "        #img = torchvision.transforms.functional.to_tensor(img.astype(np.uint8).reshape((64, 64, 3)))\n",
    "        #return {'x': x, 'y': y, 'img': img}\n",
    "        return {'x': x, 'y': y}\n",
    "    \n",
    "BATCH_SIZE = 256    \n",
    "train_dataset_text = MyDataset_text(x_train, y_train)\n",
    "dataLoader_train_text = torch.utils.data.DataLoader(train_dataset_text,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataset_text = MyDataset_text(x_test, y_test)\n",
    "dataLoader_test_text = torch.utils.data.DataLoader(test_dataset_text,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:10.947646Z",
     "iopub.status.busy": "2022-08-04T13:33:10.946739Z",
     "iopub.status.idle": "2022-08-04T13:33:10.958982Z",
     "shell.execute_reply": "2022-08-04T13:33:10.957719Z",
     "shell.execute_reply.started": "2022-08-04T13:33:10.947608Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset_img(torch.utils.data.Dataset):\n",
    "    def __init__(self, img, y):\n",
    "        #self.x = torch.tensor(x[['n_citi', 'bed', 'bath', 'sqft']].values).float()\n",
    "        self.img = img\n",
    "        self.y = torch.tensor(y.values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        img = self.img[idx]\n",
    "        img = torchvision.transforms.functional.to_tensor(img.astype(np.uint8).reshape((64, 64, 3)))\n",
    "        return {'y': y, 'img': img}\n",
    "        #return {'x': x, 'y': y}\n",
    "    \n",
    "BATCH_SIZE = 256    \n",
    "train_dataset_img = MyDataset_img(x_train_images, y_train)\n",
    "dataLoader_train_img = torch.utils.data.DataLoader(train_dataset_img,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataset_img = MyDataset_img(x_test_images, y_test)\n",
    "dataLoader_test_img = torch.utils.data.DataLoader(test_dataset_img,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:10.961905Z",
     "iopub.status.busy": "2022-08-04T13:33:10.960900Z",
     "iopub.status.idle": "2022-08-04T13:33:10.976086Z",
     "shell.execute_reply": "2022-08-04T13:33:10.974978Z",
     "shell.execute_reply.started": "2022-08-04T13:33:10.961863Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, img, y):\n",
    "        self.x = torch.tensor(x[['n_citi','bed', 'bath', 'sqft']].values).float()\n",
    "        self.img = img\n",
    "        self.y = torch.tensor(y.values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        img = self.img[idx]\n",
    "        img = torchvision.transforms.functional.to_tensor(img.astype(np.uint8).reshape((64, 64, 3)))\n",
    "        return {'x': x, 'y': y, 'img': img}\n",
    "    \n",
    "BATCH_SIZE = 256    \n",
    "train_dataset = MyDataset(x_train,x_train_images, y_train)\n",
    "dataLoader_train = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(x_test,x_test_images, y_test)\n",
    "dataLoader_test = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:10.979457Z",
     "iopub.status.busy": "2022-08-04T13:33:10.978313Z",
     "iopub.status.idle": "2022-08-04T13:33:11.004287Z",
     "shell.execute_reply": "2022-08-04T13:33:11.002893Z",
     "shell.execute_reply.started": "2022-08-04T13:33:10.979412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_img(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flatten): Sequential(\n",
      "    (0): AdaptiveMaxPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (final_fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model_img(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5, 5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_shape, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.final_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = self.conv(img)\n",
    "        img = self.flatten(img) \n",
    "        #x = self.fc(x)\n",
    "        #combined = torch.cat((img, x), 1)\n",
    "        price = self.final_fc(img)\n",
    "        return price\n",
    "    \n",
    "model_img = Model_img(3)\n",
    "print(model_img)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_img.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:11.006560Z",
     "iopub.status.busy": "2022-08-04T13:33:11.005894Z",
     "iopub.status.idle": "2022-08-04T13:33:11.015695Z",
     "shell.execute_reply": "2022-08-04T13:33:11.014613Z",
     "shell.execute_reply.started": "2022-08-04T13:33:11.006524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\n\\nn_epochs = 10\\nprint(\\'started!\\')\\ntrain_losses = []\\ntest_losses = []\\nfor epoch in range(n_epochs):\\n    train_batch_loss = 0\\n    model_img.train()\\n    for step, batch in enumerate(dataLoader_train):\\n        x = batch[\"x\"]\\n        img = batch[\"img\"]\\n        y = batch[\"y\"]\\n\\n        optimizer.zero_grad()\\n        outputs = model_img(img = img)\\n        loss = criterion(outputs[:,0], y)\\n        loss.backward()\\n        optimizer.step()\\n        train_batch_loss += loss.item()\\n        optimizer.step()\\n        optimizer.zero_grad()\\n\\n    test_batch_loss = 0\\n    model_img.eval()\\n    with torch.no_grad():\\n        for step, batch in enumerate(dataLoader_test):\\n            x = batch[\"x\"]\\n            img = batch[\"img\"]\\n            y = batch[\"y\"]\\n            outputs = model_img(img = img)\\n            loss = criterion(outputs[:,0], y)\\n            test_batch_loss += loss.item()\\n\\n    print(\\'epoch {}/{} finished with train loss: {} and test loss: {}\\'.format(epoch+1, n_epochs,\\n                                                                              train_batch_loss / len(dataLoader_train),\\n                                                                              test_batch_loss / len(dataLoader_test)))\\n    train_losses.append(train_batch_loss / len(dataLoader_train))\\n    test_losses.append(test_batch_loss / len(dataLoader_test))\\n    \\n    \\ntorch.save(model_img.state_dict(), \\'./model_img_input\\')\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "\n",
    "n_epochs = 10\n",
    "print('started!')\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    train_batch_loss = 0\n",
    "    model_img.train()\n",
    "    for step, batch in enumerate(dataLoader_train):\n",
    "        x = batch[\"x\"]\n",
    "        img = batch[\"img\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_img(img = img)\n",
    "        loss = criterion(outputs[:,0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_batch_loss = 0\n",
    "    model_img.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader_test):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "            outputs = model_img(img = img)\n",
    "            loss = criterion(outputs[:,0], y)\n",
    "            test_batch_loss += loss.item()\n",
    "\n",
    "    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n",
    "                                                                              train_batch_loss / len(dataLoader_train),\n",
    "                                                                              test_batch_loss / len(dataLoader_test)))\n",
    "    train_losses.append(train_batch_loss / len(dataLoader_train))\n",
    "    test_losses.append(test_batch_loss / len(dataLoader_test))\n",
    "    \n",
    "    \n",
    "torch.save(model_img.state_dict(), './model_img_input')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:11.018355Z",
     "iopub.status.busy": "2022-08-04T13:33:11.017638Z",
     "iopub.status.idle": "2022-08-04T13:33:11.031546Z",
     "shell.execute_reply": "2022-08-04T13:33:11.030466Z",
     "shell.execute_reply.started": "2022-08-04T13:33:11.018305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef reg_report(true, pred, name=\\'Test\\'):\\n    print(\"\\n{} Results :\\n\".format(name))\\n    print(\"RSS :\",sum((pred-true)**2))\\n    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\\n    print(\"TSS :\",sum((true-true.mean())**2))\\n    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\\n    print(\"MSE :\",((pred-true)**2).mean())\\n    print(\\'MAE :\\',(abs(pred-true)).mean())\\n    print(\\'Accuracy with 10% :\\', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\\n    \\n\\ndef eval_report(y_train, pred_train,y_test, pred_test):\\n    reg_report(y_train, pred_train, name=\\'Train\\')\\n    reg_report(y_test, pred_test, name=\\'Test\\')\\n    \\ndef res(dataLoader, name = \\'Test\\'):  \\n    trues = []\\n    preds = []\\n    model_img.eval()\\n    with torch.no_grad():\\n        for step, batch in enumerate(dataLoader):\\n            x = batch[\"x\"]\\n            img = batch[\"img\"]\\n            y = batch[\"y\"]\\n\\n            outputs = model_img(img = img)\\n\\n            trues = trues + y.tolist()\\n            preds = preds + outputs[:,0].tolist()\\n\\n\\n    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\\n\\nres(dataLoader_test, name = \\'Test\\')\\nres(dataLoader_train, name = \\'Train\\')\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def reg_report(true, pred, name='Test'):\n",
    "    print(\"\\n{} Results :\\n\".format(name))\n",
    "    print(\"RSS :\",sum((pred-true)**2))\n",
    "    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\n",
    "    print(\"TSS :\",sum((true-true.mean())**2))\n",
    "    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\n",
    "    print(\"MSE :\",((pred-true)**2).mean())\n",
    "    print('MAE :',(abs(pred-true)).mean())\n",
    "    print('Accuracy with 10% :', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\n",
    "    \n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test):\n",
    "    reg_report(y_train, pred_train, name='Train')\n",
    "    reg_report(y_test, pred_test, name='Test')\n",
    "    \n",
    "def res(dataLoader, name = 'Test'):  \n",
    "    trues = []\n",
    "    preds = []\n",
    "    model_img.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "\n",
    "            outputs = model_img(img = img)\n",
    "\n",
    "            trues = trues + y.tolist()\n",
    "            preds = preds + outputs[:,0].tolist()\n",
    "\n",
    "\n",
    "    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\n",
    "\n",
    "res(dataLoader_test, name = 'Test')\n",
    "res(dataLoader_train, name = 'Train')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:11.033655Z",
     "iopub.status.busy": "2022-08-04T13:33:11.033165Z",
     "iopub.status.idle": "2022-08-04T13:33:11.046095Z",
     "shell.execute_reply": "2022-08-04T13:33:11.044807Z",
     "shell.execute_reply.started": "2022-08-04T13:33:11.033619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n\\nplt.style.use(\"ggplot\")\\nplt.figure()\\nplt.plot(np.arange(0,len(train_losses)), train_losses, label=\"train_loss\")\\nplt.plot(np.arange(0, len(test_losses)), test_losses, label=\"val_loss\")\\nplt.title(\"Training and val Losses\")\\nplt.xlabel(\"Epoch #\")\\nplt.ylabel(\"Losses\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,len(train_losses)), train_losses, label=\"train_loss\")\n",
    "plt.plot(np.arange(0, len(test_losses)), test_losses, label=\"val_loss\")\n",
    "plt.title(\"Training and val Losses\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:36:55.118235Z",
     "iopub.status.busy": "2022-08-04T13:36:55.117284Z",
     "iopub.status.idle": "2022-08-04T13:36:55.141378Z",
     "shell.execute_reply": "2022-08-04T13:36:55.139794Z",
     "shell.execute_reply.started": "2022-08-04T13:36:55.118192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_text(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flatten): Sequential(\n",
      "    (0): AdaptiveMaxPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (final_fc): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model_text(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5, 5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_shape, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.final_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #img = self.conv(img)\n",
    "        #img = self.flatten(img) \n",
    "        x = self.fc(x)\n",
    "        #combined = torch.cat((img, x), 1)\n",
    "        price = self.final_fc(x)\n",
    "        return price\n",
    "    \n",
    "model_text = Model_text(4)\n",
    "print(model_text)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_text.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:36:57.769766Z",
     "iopub.status.busy": "2022-08-04T13:36:57.769395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started!\n",
      "epoch 1/50 finished with train loss: 437007157540.5714 and test loss: 97879577031.11111\n",
      "epoch 2/50 finished with train loss: 103736812105.14285 and test loss: 94723802453.33333\n",
      "epoch 3/50 finished with train loss: 100761466002.28572 and test loss: 93477894826.66667\n",
      "epoch 4/50 finished with train loss: 100136980284.95238 and test loss: 94729922332.44444\n",
      "epoch 5/50 finished with train loss: 100064843288.38095 and test loss: 92815931164.44444\n",
      "epoch 6/50 finished with train loss: 99421043760.7619 and test loss: 93575280412.44444\n",
      "epoch 7/50 finished with train loss: 99636274907.42857 and test loss: 92864044600.88889\n",
      "epoch 8/50 finished with train loss: 100823873048.38095 and test loss: 93579129742.22223\n",
      "epoch 9/50 finished with train loss: 99701705094.09525 and test loss: 92737049031.11111\n",
      "epoch 10/50 finished with train loss: 99535383990.85715 and test loss: 92810834375.11111\n",
      "epoch 11/50 finished with train loss: 100252675120.7619 and test loss: 92722949688.88889\n",
      "epoch 12/50 finished with train loss: 99578302464.0 and test loss: 92561301276.44444\n",
      "epoch 13/50 finished with train loss: 100775449746.28572 and test loss: 93100216775.11111\n",
      "epoch 14/50 finished with train loss: 99560007875.04762 and test loss: 92782075904.0\n",
      "epoch 15/50 finished with train loss: 100053825243.42857 and test loss: 93209282332.44444\n",
      "epoch 16/50 finished with train loss: 100449474462.4762 and test loss: 94974789859.55556\n",
      "epoch 17/50 finished with train loss: 100297307184.7619 and test loss: 92772517205.33333\n",
      "epoch 18/50 finished with train loss: 99422535582.4762 and test loss: 92821696512.0\n",
      "epoch 19/50 finished with train loss: 99767190674.28572 and test loss: 96531571143.11111\n",
      "epoch 20/50 finished with train loss: 100609174381.71428 and test loss: 92927578112.0\n",
      "epoch 21/50 finished with train loss: 99946022034.28572 and test loss: 92912537600.0\n",
      "epoch 22/50 finished with train loss: 99407855030.85715 and test loss: 92647734840.88889\n",
      "epoch 23/50 finished with train loss: 99314763483.42857 and test loss: 92729962951.11111\n",
      "epoch 24/50 finished with train loss: 100143459766.85715 and test loss: 92837490688.0\n",
      "epoch 25/50 finished with train loss: 100981487908.57143 and test loss: 92751427811.55556\n",
      "epoch 26/50 finished with train loss: 99901926546.28572 and test loss: 94058755868.44444\n",
      "epoch 27/50 finished with train loss: 99835194026.66667 and test loss: 92833101141.33333\n",
      "epoch 28/50 finished with train loss: 99728135704.38095 and test loss: 93110745315.55556\n",
      "epoch 29/50 finished with train loss: 99501103201.5238 and test loss: 92779153180.44444\n",
      "epoch 30/50 finished with train loss: 99485324044.19048 and test loss: 94151001884.44444\n",
      "epoch 31/50 finished with train loss: 99925966945.5238 and test loss: 93936338261.33333\n",
      "epoch 32/50 finished with train loss: 99863878704.7619 and test loss: 94557943580.44444\n",
      "epoch 33/50 finished with train loss: 100018695216.7619 and test loss: 92603006520.88889\n",
      "epoch 34/50 finished with train loss: 99792896585.14285 and test loss: 93198868935.11111\n",
      "epoch 35/50 finished with train loss: 100266876928.0 and test loss: 92686921728.0\n",
      "epoch 36/50 finished with train loss: 99531839585.5238 and test loss: 92610286478.22223\n",
      "epoch 37/50 finished with train loss: 99716695771.42857 and test loss: 92897362375.11111\n",
      "epoch 38/50 finished with train loss: 99608957220.57143 and test loss: 92872178346.66667\n",
      "epoch 39/50 finished with train loss: 99292390351.2381 and test loss: 92737311175.11111\n",
      "epoch 40/50 finished with train loss: 99811734674.28572 and test loss: 92981262791.11111\n",
      "epoch 41/50 finished with train loss: 100543985956.57143 and test loss: 92603263203.55556\n",
      "epoch 42/50 finished with train loss: 101054285531.42857 and test loss: 92516892672.0\n",
      "epoch 43/50 finished with train loss: 99129487164.95238 and test loss: 92576169756.44444\n",
      "epoch 44/50 finished with train loss: 99375861955.04762 and test loss: 92470966954.66667\n",
      "epoch 45/50 finished with train loss: 99470881158.09525 and test loss: 92659554076.44444\n",
      "epoch 46/50 finished with train loss: 100086728021.33333 and test loss: 92624393557.33333\n",
      "epoch 47/50 finished with train loss: 99668555093.33333 and test loss: 92654935153.77777\n",
      "epoch 48/50 finished with train loss: 99612756065.5238 and test loss: 97134272739.55556\n",
      "epoch 49/50 finished with train loss: 100064259510.85715 and test loss: 92814110720.0\n",
      "epoch 50/50 finished with train loss: 99482221226.66667 and test loss: 93568209351.11111\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 50\n",
    "print('started!')\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    train_batch_loss = 0\n",
    "    model_text.train()\n",
    "    for step, batch in enumerate(dataLoader_train):\n",
    "        x = batch[\"x\"]\n",
    "        img = batch[\"img\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_text(x = x)\n",
    "        loss = criterion(outputs[:,0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_batch_loss = 0\n",
    "    model_text.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader_test):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "            outputs = model_text(x = x)\n",
    "            loss = criterion(outputs[:,0], y)\n",
    "            test_batch_loss += loss.item()\n",
    "\n",
    "    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs,\n",
    "                                                                              train_batch_loss / len(dataLoader_train),\n",
    "                                                                              test_batch_loss / len(dataLoader_test)))\n",
    "    train_losses.append(train_batch_loss / len(dataLoader_train))\n",
    "    test_losses.append(test_batch_loss / len(dataLoader_test))\n",
    "    \n",
    "    \n",
    "torch.save(model_img.state_dict(), './model_text_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T13:33:11.314856Z",
     "iopub.status.busy": "2022-08-04T13:33:11.314493Z",
     "iopub.status.idle": "2022-08-04T13:33:11.352029Z",
     "shell.execute_reply": "2022-08-04T13:33:11.350628Z",
     "shell.execute_reply.started": "2022-08-04T13:33:11.314820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results :\n",
      "\n",
      "RSS : 429217899269622.25\n",
      "RSE : 305929.8734985313\n",
      "TSS : 616943636836547.1\n",
      "R Squared : 0.30428344885687\n",
      "MSE : 93552288419.70943\n",
      "MAE : 223416.7655092088\n",
      "Accuracy with 10% : 0.17545771578029642\n",
      "\n",
      "Train Results :\n",
      "\n",
      "RSS : 1067009880798253.5\n",
      "RSE : 315741.3473264107\n",
      "TSS : 1549134104234102.5\n",
      "R Squared : 0.31122174776096156\n",
      "MSE : 99673972984.42525\n",
      "MAE : 227825.46787570062\n",
      "Accuracy with 10% : 0.18561419897244277\n"
     ]
    }
   ],
   "source": [
    "def reg_report(true, pred, name='Test'):\n",
    "    print(\"\\n{} Results :\\n\".format(name))\n",
    "    print(\"RSS :\",sum((pred-true)**2))\n",
    "    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\n",
    "    print(\"TSS :\",sum((true-true.mean())**2))\n",
    "    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\n",
    "    print(\"MSE :\",((pred-true)**2).mean())\n",
    "    print('MAE :',(abs(pred-true)).mean())\n",
    "    print('Accuracy with 10% :', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\n",
    "    \n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test):\n",
    "    reg_report(y_train, pred_train, name='Train')\n",
    "    reg_report(y_test, pred_test, name='Test')\n",
    "    \n",
    "def res(dataLoader, name = 'Test'):  \n",
    "    trues = []\n",
    "    preds = []\n",
    "    model_text.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "\n",
    "            outputs = model_text(x = x)\n",
    "\n",
    "            trues = trues + y.tolist()\n",
    "            preds = preds + outputs[:,0].tolist()\n",
    "\n",
    "\n",
    "    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\n",
    "\n",
    "res(dataLoader_test, name = 'Test')\n",
    "res(dataLoader_train, name = 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-04T13:33:11.353404Z",
     "iopub.status.idle": "2022-08-04T13:33:11.354158Z",
     "shell.execute_reply": "2022-08-04T13:33:11.353909Z",
     "shell.execute_reply.started": "2022-08-04T13:33:11.353883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,len(train_losses)), train_losses, label=\"train_loss\")\n",
    "plt.plot(np.arange(0, len(test_losses)), test_losses, label=\"val_loss\")\n",
    "plt.title(\"Training and val Losses\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
